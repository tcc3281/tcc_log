# ğŸš€ TCC Log - AI-Powered Learning Journal

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)](https://postgresql.org/)
[![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)](https://langchain.com/)
[![LM Studio](https://img.shields.io/badge/LM%20Studio-FF6B35?style=for-the-badge&logo=openai&logoColor=white)](https://lmstudio.ai/)

> **á»¨ng dá»¥ng ghi chÃº há»c táº­p thÃ´ng minh tÃ­ch há»£p AI** - NÃ¢ng cao tráº£i nghiá»‡m há»c táº­p vá»›i sá»©c máº¡nh cá»§a Artificial Intelligence

## ğŸ“– Tá»•ng quan

TCC Log lÃ  má»™t á»©ng dá»¥ng web full-stack hiá»‡n Ä‘áº¡i Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»— trá»£ há»c táº­p vÃ  tá»• chá»©c kiáº¿n thá»©c má»™t cÃ¡ch thÃ´ng minh. Vá»›i sá»± tÃ­ch há»£p sÃ¢u sáº¯c cá»§a AI models thÃ´ng qua LM Studio vÃ  LangChain, á»©ng dá»¥ng cung cáº¥p má»™t ná»n táº£ng toÃ n diá»‡n cho viá»‡c ghi chÃº, phÃ¢n tÃ­ch ná»™i dung, vÃ  tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh há»c táº­p vá»›i kháº£ nÄƒng streaming real-time.

### ğŸ¯ Má»¥c tiÃªu
- **Tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh há»c táº­p** thÃ´ng qua AI-powered insights vÃ  analysis
- **Streaming AI Chat** vá»›i real-time response generation cho tráº£i nghiá»‡m tÆ°Æ¡ng tÃ¡c mÆ°á»£t mÃ 
- **Intelligent SQL Analysis** vá»›i kháº£ nÄƒng auto-detect vÃ  execute database queries
- **Multi-modal AI Features** bao gá»“m content analysis, writing improvement, vÃ  mood tracking
- **Tá»• chá»©c kiáº¿n thá»©c** má»™t cÃ¡ch khoa há»c vá»›i topic management vÃ  tagging system

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```mermaid
graph TB
    subgraph "Frontend Layer"
        A[Next.js 15 App Router]
        A1[React Components]
        A2[TailwindCSS]
        A3[TypeScript]
    end
    
    subgraph "Backend Layer"
        B[FastAPI Application]
        B1[API Routes]
        B2[Authentication]
        B3[File Management]
        B4[CRUD Operations]
    end
    
    subgraph "AI Engine"
        C[LM Studio Local Server]
        C1[LangChain Agent]
        C2[SQL Tool Integration]
        C3[Streaming Handler]
        C4[Prompt Manager]
    end
    
    subgraph "Data Layer"
        D[PostgreSQL Database]
        D1[User Management]
        D2[Journal Entries]
        D3[Topics & Tags]
        D4[File Storage]
    end
    
    A --> B
    B --> C
    B --> D
    C1 --> C2
    C1 --> D
    
    style C fill:#ff6b35
    style A fill:#000000,color:#ffffff
    style B fill:#005571
    style D fill:#316192
```

### ğŸ› ï¸ Stack cÃ´ng nghá»‡

```mermaid
graph LR
    subgraph "Backend Stack"
        B1[FastAPI] --> B2[SQLAlchemy ORM]
        B2 --> B3[PostgreSQL]
        B4[Alembic] --> B3
        B5[Pydantic] --> B1
    end
    
    subgraph "Frontend Stack"
        F1[Next.js 15] --> F2[React 19]
        F2 --> F3[TailwindCSS]
        F3 --> F4[TypeScript]
        F5[React Hook Form] --> F2
    end
    
    subgraph "AI/ML Stack"
        A1[LM Studio] --> A2[LangChain]
        A2 --> A3[OpenAI API Compatible]
        A4[Custom Streaming] --> A1
        A5[SQL Tools] --> A2
    end
    
    subgraph "DevOps & Tools"
        D1[Docker Compose] --> D2[PostgreSQL Container]
        D3[Python 3.10+] --> B1
        D4[Node.js 18+] --> F1
    end
    
    style A1 fill:#ff6b35
    style F1 fill:#000000,color:#ffffff
    style B1 fill:#005571
    style B3 fill:#316192
```

#### Backend Technologies
- **FastAPI** - Modern Python web framework vá»›i automatic API documentation
- **SQLAlchemy** - Powerful ORM vá»›i async support vÃ  relationship management
- **PostgreSQL** - Reliable relational database vá»›i JSON support
- **Alembic** - Database migration tool cho version control
- **Pydantic** - Data validation vÃ  serialization vá»›i type hints

#### Frontend Technologies  
- **Next.js 15** - React framework vá»›i App Router vÃ  server components
- **React 19** - Latest React vá»›i improved performance vÃ  features
- **TailwindCSS** - Utility-first CSS framework cho responsive design
- **TypeScript** - Type-safe development vá»›i improved DX
- **React Hook Form** - Efficient form handling vá»›i validation

#### AI/ML Technologies
- **LM Studio** - Local AI model serving vá»›i OpenAI-compatible API
- **LangChain** - Framework cho LLM applications vá»›i tool integration
- **Custom Streaming** - Real-time token streaming implementation
- **SQL Tools** - Intelligent database interaction vá»›i auto-execution
- **Prompt Management** - Dynamic prompt templates cho different AI tasks

## âœ¨ TÃ­nh nÄƒng chÃ­nh

### ğŸ“ Core Journal Management
```mermaid
graph TD
    A[Journal Entry Creation] --> B[Rich Text Editor]
    B --> C[Markdown Support]
    C --> D[LaTeX Math Rendering]
    
    A --> E[Topic Management]
    E --> F[Hierarchical Topics]
    F --> G[Tag System]
    
    A --> H[File Attachments]
    H --> I[Image Upload]
    H --> J[Document Support]
    
    A --> K[Metadata]
    K --> L[Date & Location]
    K --> M[Mood Tracking]
```

- **Advanced Rich Text Editor** vá»›i há»— trá»£ Markdown vÃ  LaTeX rendering
- **Hierarchical Topic System** cho viá»‡c tá»• chá»©c ná»™i dung theo chá»§ Ä‘á»
- **Flexible Tag System** vá»›i auto-suggestions vÃ  filtering
- **File Upload System** há»— trá»£ images, documents vÃ  multimedia files
- **Metadata Management** vá»›i date-based organization vÃ  mood tracking
- **Profile Management** vá»›i avatar upload vÃ  personal preferences

### ğŸ¤– AI-Powered Features

```mermaid
graph TB
    subgraph "AI Core Engine"
        A[LM Studio Local Server]
        A --> B[LangChain Agent]
        A --> C[Direct LLM Streaming]
    end
    
    subgraph "AI Features"
        D[Streaming Chat]
        E[Content Analysis]
        F[Writing Enhancement]
        G[SQL Intelligence]
        H[Prompt Generation]
    end
    
    subgraph "Analysis Types"
        E --> E1[General Analysis]
        E --> E2[Mood Analysis] 
        E --> E3[Content Summary]
        E --> E4[Learning Insights]
    end
    
    subgraph "Writing Tools"
        F --> F1[Grammar Check]
        F --> F2[Style Improvement]
        F --> F3[Vocabulary Enhancement]
        F --> F4[Structure Analysis]
    end
    
    B --> D
    B --> E
    B --> F
    B --> G
    C --> D
    
    style A fill:#ff6b35
    style B fill:#1C3C3C
```

#### ğŸ’¬ Intelligent Streaming Chat
- **Real-time Token Streaming** vá»›i true token-level response generation
- **Think/Answer Separation** - theo dÃµi quÃ¡ trÃ¬nh suy nghÄ© cá»§a AI
- **LaTeX Mathematical Rendering** cho cÃ´ng thá»©c toÃ¡n há»c phá»©c táº¡p
- **Performance Monitoring** vá»›i tokens/second vÃ  inference time tracking
- **Multiple Streaming Modes** tá»« basic Ä‘áº¿n advanced vá»›i tool integration
- **Context-aware Responses** dá»±a trÃªn journal content vÃ  conversation history

#### ğŸ“Š Advanced Content Analysis
- **General Analysis**: PhÃ¢n tÃ­ch tá»•ng quan vá» cháº¥t lÆ°á»£ng vÃ  cáº¥u trÃºc ná»™i dung
- **Mood Analysis**: ÄÃ¡nh giÃ¡ tráº¡ng thÃ¡i cáº£m xÃºc vÃ  mental health patterns
- **Content Summary**: TÃ³m táº¯t key points vÃ  main takeaways
- **Learning Insights**: TrÃ­ch xuáº¥t patterns vÃ  Ä‘Æ°a ra recommendations
- **Progress Tracking**: Theo dÃµi learning journey theo thá»i gian

#### âœï¸ Intelligent Writing Enhancement
- **Grammar & Spell Correction**: Tá»± Ä‘á»™ng detect vÃ  suggest improvements
- **Style Enhancement**: Cáº£i thiá»‡n clarity, readability vÃ  flow
- **Vocabulary Enrichment**: Suggest synonyms vÃ  academic terminology
- **Structure Optimization**: ÄÃ¡nh giÃ¡ logic flow vÃ  organization
- **Tone Adjustment**: Äiá»u chá»‰nh tone phÃ¹ há»£p vá»›i context

#### ğŸ” SQL Intelligence System
- **Auto-detect Database Queries**: Tá»± Ä‘á»™ng nháº­n biáº¿t cÃ¢u há»i liÃªn quan database
- **Schema Injection**: Dynamic injection cá»§a database schema vÃ o prompts
- **SQL Auto-execution**: Tá»± Ä‘á»™ng execute SQL queries tá»« AI responses
- **Result Formatting**: Beautiful markdown table formatting cho query results
- **Error Handling**: Comprehensive error handling vá»›i meaningful messages

### ğŸ” Security & Authentication

```mermaid
graph TD
    A[User Authentication] --> B[JWT Token System]
    B --> C[Access Token]
    B --> D[Refresh Token]
    
    E[Authorization] --> F[Role-based Access Control]
    F --> G[User Role]
    F --> H[Admin Role]
    
    I[Data Security] --> J[Password Hashing bcrypt]
    I --> K[Input Validation Pydantic]
    I --> L[SQL Injection Protection]
    
    M[File Security] --> N[Type Validation]
    M --> O[Size Limits]
    M --> P[Secure Upload Path]
    
    Q[API Security] --> R[Rate Limiting]
    Q --> S[CORS Configuration]
    Q --> T[Request Validation]
```

- **JWT-based Authentication** vá»›i secure token management vÃ  refresh mechanism
- **Role-based Access Control** (User, Admin) vá»›i granular permissions
- **Password Security** vá»›i bcrypt hashing vÃ  salt generation
- **Input Validation** comprehensive vá»›i Pydantic schemas
- **File Upload Security** vá»›i type checking, size limits vÃ  path sanitization
- **API Protection** vá»›i rate limiting, CORS configuration vÃ  request validation

## ğŸš€ CÃ i Ä‘áº·t vÃ  Triá»ƒn khai

### ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

```mermaid
graph LR
    subgraph "Development Requirements"
        A[Python 3.10+]
        B[Node.js 18+]
        C[PostgreSQL 14+]
        D[LM Studio Desktop App]
    end
    
    subgraph "Production Requirements"
        E[Docker & Docker Compose]
        F[Git]
        G[4GB+ RAM]
        H[2GB+ Storage]
    end
    
    A --> E
    B --> E
    C --> E
    D --> E
```

- **Python 3.10+** vá»›i pip package manager
- **Node.js 18+** vá»›i npm/yarn package manager  
- **PostgreSQL 14+** vá»›i database creation privileges
- **LM Studio** desktop application cho local AI models
- **Docker & Docker Compose** (recommended) cho containerized deployment
- **Git** cho version control vÃ  repository cloning

### ğŸ¯ Quick Start vá»›i Docker (Khuyáº¿n nghá»‹)

```mermaid
sequenceDiagram
    participant User
    participant Docker
    participant DB as PostgreSQL
    participant Backend as FastAPI
    participant Frontend as Next.js
    participant LM as LM Studio
    
    User->>Docker: docker-compose up
    Docker->>DB: Start PostgreSQL container
    Docker->>Backend: Start FastAPI container
    Docker->>Frontend: Start Next.js container
    
    Backend->>DB: Run migrations
    Backend->>DB: Seed initial data
    
    User->>LM: Start LM Studio manually
    LM->>Backend: Provide AI endpoint
    
    User->>Frontend: Access http://localhost:3000
    Frontend->>Backend: API calls
    Backend->>LM: AI requests
```

#### Windows (PowerShell)
```powershell
# Clone repository
git clone https://github.com/your-username/tcc-log.git
cd tcc-log

# Run setup script (builds vÃ  starts all containers)
.\scripts\run_docker.ps1

# Access application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000
# API Documentation: http://localhost:8000/docs
```

#### Linux/macOS
```bash
# Clone repository
git clone https://github.com/your-username/tcc-log.git
cd tcc-log

# Start with Docker Compose
docker-compose up --build -d

# Check container status
docker-compose ps

# View logs
docker-compose logs -f
```

### ğŸ”§ Installation

#### 1. Clone Repository
```bash
git clone https://github.com/your-username/tcc-log.git
cd tcc-log
```

#### 2. Backend Setup
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate
# macOS/Linux  
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Environment Configuration
```bash
# Copy environment template
cp .env.example .env

# Edit .env with your configurations
nano .env
```

**Environment Variables:**
```env
# Database
DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/tcc_log
TEST_DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/tcc_log_test

# Security
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI Configuration
OPENAI_API_KEY=your-openai-api-key
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_API_KEY=your-lm-studio-key

# File Upload
UPLOAD_DIR=uploads
MAX_FILE_SIZE=10485760  # 10MB
```

#### 4. Database Migration
```bash
# Initialize Alembic (if not done)
alembic init alembic

# Create and run migrations
alembic revision --autogenerate -m "Initial migration"
alembic upgrade head

# Seed sample data (optional)
python -m app.seed_data
```

#### 5. Frontend Setup
```bash
cd frontend

# Install dependencies
npm install
# or
yarn install

# Create environment file
cp .env.local.example .env.local

# Edit frontend environment
nano .env.local
```

**Frontend Environment:**
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_APP_NAME=TCC Log
NEXT_PUBLIC_MAX_FILE_SIZE=10485760
```

## ğŸ® Running the Application

### âš¡ Development Mode

```mermaid
sequenceDiagram
    participant Dev as Developer
    participant Docker as Docker Compose
    participant DB as PostgreSQL Container
    participant Backend as FastAPI Container
    participant Frontend as Next.js Container
    participant LM as LM Studio
    
    Dev->>Docker: docker-compose up --build
    Docker->>DB: Start PostgreSQL
    Docker->>Backend: Start FastAPI
    Docker->>Frontend: Start Next.js
    
    Backend->>DB: Run Alembic migrations
    Backend->>DB: Seed initial data
    
    Dev->>LM: Start LM Studio locally
    LM->>Backend: Provide AI endpoint (:1234)
    
    Frontend->>Backend: API calls (:8000)
    Backend->>LM: AI requests
    Backend->>DB: Data operations
    
    Note over Dev: Access at http://localhost:3000
```

#### Access Points:
- **Frontend Application**: http://localhost:3000
- **Backend API**: http://localhost:8000  
- **API Documentation**: http://localhost:8000/docs
- **Alternative API Docs**: http://localhost:8000/redoc
- **AI Chat Interface**: http://localhost:3000/ai

#### Manual Development Setup:
```bash
# Terminal 1: Backend
cd tcc-log
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Terminal 2: Frontend  
cd frontend
npm run dev

# Terminal 3: LM Studio (if not using Docker)
# Start LM Studio application and load a model
```

### ğŸ­ Production Deployment

```mermaid
graph TD
    subgraph "Production Environment"
        A[Load Balancer] --> B[FastAPI Containers]
        A --> C[Next.js Containers]
        
        B --> D[PostgreSQL Cluster]
        B --> E[LM Studio Servers]
        
        F[Redis Cache] --> B
        G[File Storage] --> B
        H[Monitoring] --> B
        H --> C
    end
    
    subgraph "Scaling Options"
        I[Horizontal Scaling]
        I --> J[Multiple FastAPI Instances]
        I --> K[Database Read Replicas]
        I --> L[CDN for Static Assets]
    end
    
    B --> F
    C --> G
```

#### Production with Docker:
```bash
# Build production images
docker-compose -f docker-compose.prod.yml build

# Start production stack
docker-compose -f docker-compose.prod.yml up -d

# Scale specific services
docker-compose -f docker-compose.prod.yml up -d --scale backend=3
```

## ğŸ§ª Testing & Quality Assurance

### ğŸ” Testing Architecture

```mermaid
graph TB
    subgraph "Test Categories"
        A[Unit Tests] --> A1[Individual Functions]
        A --> A2[Class Methods]
        A --> A3[API Endpoints]
        
        B[Integration Tests] --> B1[Database Operations]
        B --> B2[AI Service Integration]
        B --> B3[End-to-End Workflows]
        
        C[Performance Tests] --> C1[Load Testing]
        C --> C2[Streaming Performance]
        C --> C3[Database Query Optimization]
    end
    
    subgraph "Test Tools"
        D[pytest] --> E[Async Test Support]
        F[pytest-asyncio] --> G[AI Testing]
        H[pytest-cov] --> I[Coverage Reports]
    end
    
    A1 --> D
    B1 --> F
    C1 --> H
```

### Running Tests
```bash
# Install test dependencies
pip install pytest pytest-asyncio pytest-cov httpx

# Run all tests
pytest

# Run with coverage reporting
pytest --cov=app --cov-report=html --cov-report=term

# Run specific test categories
pytest tests/unit/          # Unit tests only
pytest tests/integration/   # Integration tests only
pytest tests/ai/           # AI-specific tests

# Run tests with verbose output
pytest -v -s

# Run specific test file
pytest tests/test_ai_features.py -v
```

### AI Testing Examples
```bash
# Test AI service connectivity
pytest tests/ai/test_lm_studio_connection.py

# Test streaming functionality
pytest tests/ai/test_streaming_responses.py

# Test SQL tool integration
pytest tests/ai/test_sql_tools.py

# Performance benchmarks
pytest tests/performance/ --benchmark-only
```

## ğŸ›¡ï¸ Security & Best Practices

### ğŸ” Security Implementation

```mermaid
graph TD
    subgraph "Authentication Layer"
        A[JWT Tokens] --> B[Access Token]
        A --> C[Refresh Token]
        B --> D[30min Expiry]
        C --> E[7 Day Expiry]
    end
    
    subgraph "Authorization Layer"
        F[Role-Based Access] --> G[User Role]
        F --> H[Admin Role]
        G --> I[Own Resources Only]
        H --> J[System Administration]
    end
    
    subgraph "Data Protection"
        K[Input Validation] --> L[Pydantic Schemas]
        M[SQL Injection Prevention] --> N[SQLAlchemy ORM]
        O[File Upload Security] --> P[Type & Size Validation]
        Q[Password Security] --> R[bcrypt + Salt]
    end
    
    subgraph "API Security"
        S[Rate Limiting] --> T[Request Throttling]
        U[CORS Configuration] --> V[Origin Validation]
        W[Request Validation] --> X[Schema Enforcement]
    end
    
    style A fill:#1C3C3C,color:#ffffff
    style F fill:#005571
    style K fill:#316192
    style S fill:#ff6b35
```

### Best Practices Implementation

#### Environment Security
```bash
# Use strong secret keys
SECRET_KEY=$(openssl rand -hex 32)

# Secure database connections
DATABASE_URL=postgresql://user:strong_password@localhost:5432/tcc_log

# API rate limiting
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600  # 1 hour

# File upload limits
MAX_FILE_SIZE_MB=10
ALLOWED_FILE_TYPES=jpg,jpeg,png,gif,pdf,doc,docx,txt,md
```

#### Code Security Practices
```python
# Input validation example
from pydantic import BaseModel, validator
from typing import Optional

class SecureEntryCreate(BaseModel):
    title: str
    content: str
    topic_id: int
    
    @validator('title')
    def validate_title(cls, v):
        if len(v) > 200:
            raise ValueError('Title too long')
        return v.strip()
    
    @validator('content')
    def validate_content(cls, v):
        if len(v) > 50000:  # 50KB limit
            raise ValueError('Content too long')
        return v
```

## ğŸ“ˆ Monitoring & Performance

### ğŸ“Š Application Monitoring

```mermaid
graph LR
    subgraph "Real-time Metrics"
        A[Request Latency] --> A1[API Response Times]
        B[AI Performance] --> B1[Tokens/Second]
        C[Database Performance] --> C1[Query Execution Time]
        D[Memory Usage] --> D1[Resource Consumption]
    end
    
    subgraph "Health Monitoring"
        E[Service Health] --> E1[LM Studio Connection]
        E --> E2[Database Connection]
        E --> E3[API Endpoint Status]
    end
    
    subgraph "Error Tracking"
        F[Application Errors] --> F1[Error Rates]
        F --> F2[Exception Details]
        F --> F3[Performance Issues]
    end
    
    subgraph "User Analytics"
        G[Usage Patterns] --> G1[Feature Adoption]
        G --> G2[User Engagement]
        G --> G3[AI Interaction Stats]
    end
```

### Performance Optimization

#### Database Optimization
```sql
-- Recommended indexes for performance
CREATE INDEX idx_entries_user_date ON entries(user_id, entry_date DESC);
CREATE INDEX idx_entries_topic ON entries(topic_id);
CREATE INDEX idx_entries_tags ON entry_tags(entry_id, tag_id);
CREATE INDEX idx_users_email ON users(email);

-- Full-text search index
CREATE INDEX idx_entries_content_fts ON entries USING gin(to_tsvector('english', content));
```

#### Caching Strategy
```python
from functools import lru_cache
import asyncio

# Cache AI model instances
@lru_cache(maxsize=10)
def get_cached_ai_instance(model: str, temperature: float):
    return get_chatopen_ai_instance(model, temperature)

# Cache database schema
@lru_cache(maxsize=1)
async def get_cached_db_schema():
    # Cache schema for 5 minutes
    return await get_database_schema()
```

## ğŸš€ Deployment Guide

### ğŸ³ Docker Production Setup

```mermaid
graph TD
    subgraph "Production Architecture"
        A[Nginx Load Balancer] --> B[FastAPI Containers]
        A --> C[Next.js Container]
        
        B --> D[PostgreSQL Master]
        B --> E[PostgreSQL Read Replica]
        B --> F[Redis Cache]
        
        G[LM Studio Server] --> B
        H[File Storage Volume] --> B
        I[Backup Service] --> D
    end
    
    subgraph "Scaling Configuration"
        J[Auto Scaling] --> K[Container Orchestration]
        L[Load Balancing] --> M[Health Checks]
        N[Resource Monitoring] --> O[Alert System]
    end
    
    style A fill:#ff6b35
    style D fill:#316192
    style G fill:#1C3C3C,color:#ffffff
```

#### Production Docker Compose
```yaml
version: '3.8'
services:
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - backend
      - frontend

  backend:
    build: 
      context: .
      dockerfile: docker/Dockerfile.backend
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/tcc_log
      - LM_STUDIO_BASE_URL=http://lm-studio:1234/v1
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  frontend:
    build:
      context: ./frontend
      dockerfile: ../docker/Dockerfile.frontend
    environment:
      - NEXT_PUBLIC_API_URL=https://your-domain.com/api

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=tcc_log
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=secure_password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups

  redis:
    image: redis:alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

### ğŸŒ Environment-specific Configuration

#### Development (.env.development)
```env
# Development settings
DEBUG=true
DATABASE_URL=postgresql://dev_user:dev_pass@localhost:5432/tcc_log_dev
LM_STUDIO_BASE_URL=http://localhost:1234/v1
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# AI Settings
DEFAULT_AI_MODEL=llama-3.1-8b-instruct
DEFAULT_TEMPERATURE=0.7
MAX_INFERENCE_TIME=60000

# File Upload
MAX_FILE_SIZE_MB=10
UPLOAD_DIR=uploads
```

#### Production (.env.production)
```env
# Production settings
DEBUG=false
DATABASE_URL=postgresql://prod_user:secure_password@postgres:5432/tcc_log
LM_STUDIO_BASE_URL=http://lm-studio:1234/v1
CORS_ORIGINS=https://your-domain.com

# Security
SECRET_KEY=your-super-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7

# Performance
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30
REDIS_URL=redis://redis:6379/0

# Monitoring
SENTRY_DSN=your-sentry-dsn
LOG_LEVEL=INFO
```

### ğŸ”§ LM Studio Configuration

```mermaid
graph TD
    A[Download LM Studio] --> B[Install Application]
    B --> C[Download AI Models]
    C --> D[Available Models]
    D --> D1[Llama Models]
    D --> D2[Mistral Models] 
    D --> D3[CodeLlama Models]
    D --> D4[Qwen Models]
    
    E[Start Local Server] --> F[Select Model]
    F --> G[Configure Settings]
    G --> H[Start Server on Port 1234]
    
    H --> I[API Endpoint: http://localhost:1234/v1]
    I --> J[Configure in .env file]
```

#### Recommended Models (HIá»†N Táº I ÄANG Sá»¬ Dá»¤NG):
- **deepseek-r1-distill-qwen-1.5b** (Docker environment default)
- **qwen/qwen3-1.7b** (Development default)  
- **llama-3.1-8b-instruct** (Alternative option)
- **phi-3-mini-instruct** (Lightweight option)

3. **Load Model** trong LM Studio interface
4. **Start Server** trÃªn port 1234
5. **Verify** connection táº¡i http://localhost:1234/v1/models

### ğŸ”„ Development Workflow (THá»°C Táº¾)

```mermaid
sequenceDiagram
    participant Dev as "Developer"
    participant Docker as "Docker Compose"
    participant Backend as "FastAPI :8000"
    participant Frontend as "Next.js :3000"
    participant LM as "LM Studio :1234"
    participant DB as "PostgreSQL :5432"
    
    Dev->>Docker: "docker-compose up --build"
    Docker->>DB: "Start PostgreSQL container"
    Docker->>Backend: "Start FastAPI container"
    Docker->>Frontend: "Start Next.js container"
    
    Backend->>DB: "Run migrations & seed data"
    Frontend->>Backend: "API calls to :8000"
    Backend->>LM: "AI requests to host.docker.internal:1234"
    
    Note over Dev: "Access at http://localhost:3000"
```

**Actual Ports:**
- Frontend: http://localhost:3000 âœ…
- Backend API: http://localhost:8000 âœ…
- API Docs: http://localhost:8000/docs âœ…
- LM Studio: http://localhost:1234 (external) âœ…
- PostgreSQL: localhost:5432 (internal) âœ…
   - **Llama 3.1 8B** - Balanced performance vÃ  quality
   - **Mistral 7B** - Fast inference vá»›i good accuracy
   - **CodeLlama 7B** - Specialized cho coding tasks
   - **Qwen 2.5 7B** - Excellent cho multilingual tasks

3. **Start Local Server:**
   ```
   - Má»Ÿ LM Studio application
   - Chá»n model tá»« library vÃ  click "Load Model"
   - Navigate Ä‘áº¿n "Local Server" tab
   - Click "Start Server" (default: port 1234)
   - Verify server status: http://localhost:1234/v1/models
   ```

4. **Configure Environment Variables:**
   ```env
   # LM Studio Configuration
   LM_STUDIO_BASE_URL=http://localhost:1234/v1
   LM_STUDIO_API_KEY=lm-studio  # hoáº·c custom key
   DEFAULT_AI_MODEL=your-model-identifier
   DEFAULT_TEMPERATURE=0.7
   DEFAULT_MAX_TOKENS=2000
   MAX_INFERENCE_TIME=60000  # 60 seconds
   ```

## ï¿½ Contributing & Development

### ğŸ”„ Development Workflow

```mermaid
gitGraph
    commit id: "Initial Setup"
    branch feature/ai-enhancement
    checkout feature/ai-enhancement
    commit id: "Add streaming"
    commit id: "Add SQL tools"
    commit id: "Add tests"
    checkout main
    merge feature/ai-enhancement
    commit id: "Release v1.1"
    branch feature/ui-improvements
    checkout feature/ui-improvements
    commit id: "New components"
    commit id: "Mobile responsive"
    checkout main
    merge feature/ui-improvements
    commit id: "Release v1.2"
```

### Development Guidelines

1. **Fork Repository** vÃ  create feature branch tá»« `main`
2. **Follow Coding Standards** (Black formatting, type hints, docstrings)
3. **Write Comprehensive Tests** cho new features vÃ  bug fixes
4. **Update Documentation** náº¿u cÃ³ API changes hoáº·c new features
5. **Submit Pull Request** vá»›i clear description vÃ  test evidence

### Code Quality Standards

```bash
# Format code vá»›i Black
black app/ tests/ --line-length 88

# Sort imports vá»›i isort
isort app/ tests/ --profile black

# Type checking vá»›i mypy
mypy app/ --ignore-missing-imports

# Linting vá»›i flake8
flake8 app/ tests/ --max-line-length 88 --extend-ignore E203,W503

# Run all quality checks
./scripts/quality_check.sh
```

### Commit Message Convention
```
type(scope): description

feat(ai): add real-time streaming chat
fix(database): resolve connection timeout issue
docs(readme): update installation guide
test(api): add comprehensive endpoint tests
refactor(sql): optimize query performance
perf(streaming): improve token throughput
```

## ğŸ“š Documentation & Resources

### ğŸ“– Additional Documentation

```mermaid
graph TD
    A[Documentation Hub] --> B[API Documentation]
    A --> C[Architecture Guides]
    A --> D[Deployment Guides]
    A --> E[Development Guides]
    
    B --> B1[OpenAPI/Swagger Docs]
    B --> B2[Endpoint Reference]
    B --> B3[Request/Response Examples]
    
    C --> C1[System Architecture]
    C --> C2[Database Schema]
    C --> C3[AI Integration Guide]
    
    D --> D1[Docker Setup]
    D --> D2[Production Deployment]
    D --> D3[Monitoring Setup]
    
    E --> E1[Local Development]
    E --> E2[Testing Guide]
    E --> E3[Contributing Guidelines]
```

#### Core Documentation Files:
- **[API Documentation](http://localhost:8000/docs)** - Interactive Swagger UI
- **[Agent Documentation](./docs/AGENT_DOCUMENTATION.md)** - LangChain Agent deep dive
- **[LM Studio Documentation](./docs/LM_STUDIO_DOCUMENTATION.md)** - AI backend architecture
- **[Database Schema](./docs/database-schema.md)** - Complete database design
- **[Frontend Components Guide](./frontend/README.md)** - React component library
- **[Deployment Guide](./docs/deployment-guide.md)** - Production deployment steps

### ğŸ“ Learning Resources

#### For Developers New to the Stack:
- **FastAPI Tutorial**: https://fastapi.tiangolo.com/tutorial/
- **Next.js Learning**: https://nextjs.org/learn
- **LangChain Documentation**: https://docs.langchain.com/
- **LM Studio Guides**: https://lmstudio.ai/docs

#### AI/ML Integration:
- **Streaming Best Practices**: [./docs/ai-streaming-guide.md](./docs/ai-streaming-guide.md)
- **Prompt Engineering**: [./docs/prompt-engineering.md](./docs/prompt-engineering.md)
- **SQL Tool Development**: [./docs/sql-tools-guide.md](./docs/sql-tools-guide.md)

## ğŸš€ Roadmap & Future Features

### ğŸ¯ Planned Enhancements

```mermaid
gantt
    title TCC Log Development Roadmap
    dateFormat  YYYY-MM-DD
    section Phase 1 - Core Features
    Basic AI Chat           :done, phase1a, 2024-01-01, 2024-02-15
    Streaming Integration   :done, phase1b, 2024-02-01, 2024-03-01
    SQL Tools              :done, phase1c, 2024-02-15, 2024-03-15
    
    section Phase 2 - Enhanced AI
    Advanced Analysis      :active, phase2a, 2024-03-01, 2024-04-15
    Writing Enhancement    :active, phase2b, 2024-03-15, 2024-04-30
    Multi-model Support    :phase2c, 2024-04-01, 2024-05-15
    
    section Phase 3 - Advanced Features
    Vector Database        :phase3a, 2024-05-01, 2024-06-15
    RAG Integration        :phase3b, 2024-05-15, 2024-07-01
    Image Analysis         :phase3c, 2024-06-01, 2024-07-15
    
    section Phase 4 - Platform Features
    Mobile Apps            :phase4a, 2024-07-01, 2024-09-01
    API Marketplace        :phase4b, 2024-08-01, 2024-10-01
    Enterprise Features    :phase4c, 2024-09-01, 2024-11-01
```

### ğŸŒŸ Upcoming Features

#### Short-term (Next 3 months):
- **Vector Database Integration** cho semantic search
- **Advanced RAG (Retrieval-Augmented Generation)** cho context-aware responses
- **Multi-model Support** vá»›i model switching capabilities
- **Enhanced Analytics Dashboard** vá»›i detailed usage metrics
- **Mobile-responsive UI** improvements

#### Medium-term (3-6 months):
- **Image Analysis** vá»›i vision models integration
- **Code Generation Assistant** specialized cho programming tasks
- **Advanced Collaboration** features vá»›i shared workspaces
- **API Rate Limiting** vÃ  usage analytics
- **Plugin System** cho third-party integrations

#### Long-term (6+ months):
- **Mobile Applications** (iOS/Android)
- **Desktop Applications** (Electron)
- **Enterprise SSO** integration
- **Advanced Security** features
- **AI Model Training** capabilities

## ğŸ“ Support & Community

### ğŸ†˜ Getting Help

```mermaid
graph TD
    A[Need Help?] --> B["Type of Issue"]
    
    B -->|Bug Report| C[GitHub Issues]
    B -->|Feature Request| D[GitHub Discussions]
    B -->|General Question| E[Community Forum]
    B -->|Security Issue| F[Security Email]
    
    C --> G[Provide Reproduction Steps]
    D --> H[Describe Use Case]
    E --> I[Search Existing Answers]
    F --> J[security@tcclog.com]
    
    G --> K[Maintainer Response]
    H --> L[Community Feedback]
    I --> M[Get Community Help]
    J --> N[Security Team Review]
```

### Contact Information:
- **ğŸ“§ General Support**: support@tcclog.com
- **ğŸ”’ Security Issues**: security@tcclog.com
- **ğŸ’¬ GitHub Discussions**: [Project Discussions](https://github.com/your-username/tcc-log/discussions)
- **ğŸ› Bug Reports**: [GitHub Issues](https://github.com/your-username/tcc-log/issues)
- **ğŸ“– Documentation**: [Wiki Pages](https://github.com/your-username/tcc-log/wiki)

### Community Guidelines:
- **Be Respectful**: Treat all community members with respect
- **Search First**: Check existing issues vÃ  discussions before posting
- **Provide Context**: Include relevant details when asking questions
- **Follow Templates**: Use provided issue vÃ  PR templates
- **Contribute Back**: Help others when you can

## ğŸ“„ License & Acknowledgments

### ğŸ“œ License
This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 TCC Log Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

### ğŸ™ Acknowledgments & Credits

```mermaid
graph LR
    subgraph "Core Technologies"
        A[FastAPI Team] --> A1[Excellent Web Framework]
        B[LangChain Community] --> B1[AI Integration Tools]
        C[Next.js Team] --> C1[Modern React Framework]
        D[PostgreSQL Team] --> D1[Reliable Database]
    end
    
    subgraph "AI/ML Ecosystem"
        E[LM Studio] --> E1[Local AI Serving]
        F[OpenAI] --> F1[API Standards]
        G[Hugging Face] --> G1[Model Repository]
        H[Python Community] --> H1[Rich Ecosystem]
    end
    
    subgraph "Development Tools"
        I[Docker] --> I1[Containerization]
        J[GitHub] --> J1[Version Control & CI/CD]
        K[VS Code] --> K1[Development Environment]
        L[Open Source Community] --> L1[Inspiration & Support]
    end
```

#### Special Thanks:
- **FastAPI & Starlette** teams cho excellent async web framework
- **LangChain** community cho comprehensive AI integration tools
- **Next.js & Vercel** team cho modern React development experience
- **PostgreSQL** team cho robust vÃ  reliable database system
- **LM Studio** cho making local AI accessible vÃ  user-friendly
- **Python & JavaScript** communities cho rich ecosystems
- **Open Source Contributors** worldwide cho inspiration vÃ  collaboration

---

<div align="center">

**Made with â¤ï¸ by TCC Log Team**

*Transforming learning through intelligent technology*

[![GitHub Stars](https://img.shields.io/github/stars/your-username/tcc-log?style=social)](https://github.com/your-username/tcc-log)
[![GitHub Forks](https://img.shields.io/github/forks/your-username/tcc-log?style=social)](https://github.com/your-username/tcc-log)
[![GitHub Issues](https://img.shields.io/github/issues/your-username/tcc-log)](https://github.com/your-username/tcc-log/issues)
[![GitHub License](https://img.shields.io/github/license/your-username/tcc-log)](https://github.com/your-username/tcc-log/blob/main/LICENSE)

[ğŸš€ Get Started](#-cÃ i-Ä‘áº·t-vÃ -triá»ƒn-khai) â€¢ [ğŸ“– Documentation](#-documentation--resources) â€¢ [ï¿½ Community](#-support--community) â€¢ [ğŸ¤ Contribute](#-contributing--development)

</div>

```mermaid
graph TD
    A[tcc_log/] --> B[ğŸ“ app/ - Backend FastAPI]
    A --> C[ğŸ“ frontend/ - Next.js UI]
    A --> D[ğŸ“ docs/ - Documentation]
    A --> E[ğŸ“ scripts/ - Utility Scripts]
    A --> F[ğŸ“ tests/ - Test Suite]
    A --> G[ğŸ“ docker/ - Container Config]
    
    B --> B1[ğŸ“ api/ - REST Endpoints]
    B --> B2[ğŸ“ ai/ - AI Integration]
    B --> B3[main.py - FastAPI App]
    B --> B4[models.py - Database Models]
    B --> B5[schemas.py - Pydantic Schemas]
    
    B1 --> B11[auth.py - Authentication]
    B1 --> B12[users.py - User Management]
    B1 --> B13[entries.py - Journal Entries]
    B1 --> B14[ai.py - AI Endpoints]
    
    B2 --> B21[agent.py - LangChain Agent]
    B2 --> B22[lm_studio.py - AI Backend]
    B2 --> B23[sql_tool.py - Database Tools]
    B2 --> B24[prompt_manager.py - Prompt Templates]
    
    C --> C1[ğŸ“ app/ - App Router Pages]
    C --> C2[ğŸ“ components/ - React Components]
    C --> C3[ğŸ“ lib/ - Utility Libraries]
    C --> C4[ğŸ“ types/ - TypeScript Types]
    
    C1 --> C11[ai/ - AI Chat Interface]
    C1 --> C12[entries/ - Journal Management]
    C1 --> C13[auth/ - Login/Register]
    
    C2 --> C21[AI/ - AI Components]
    C2 --> C22[Navigation/ - Nav Components]
    C2 --> C23[MarkdownEditor.tsx - Rich Editor]
```

### Backend Structure (`/app`)
```
app/
â”œâ”€â”€ ğŸ“„ main.py              # FastAPI application entry point
â”œâ”€â”€ ğŸ“„ database.py          # Database configuration & connection
â”œâ”€â”€ ğŸ“„ models.py            # SQLAlchemy database models
â”œâ”€â”€ ğŸ“„ schemas.py           # Pydantic validation schemas
â”œâ”€â”€ ğŸ“„ crud.py              # Database CRUD operations
â”œâ”€â”€ ğŸ“„ seed_data.py         # Initial data seeding
â”œâ”€â”€ ğŸ“ api/                 # REST API endpoints
â”‚   â”œâ”€â”€ ğŸ“„ auth.py          # Authentication & authorization
â”‚   â”œâ”€â”€ ğŸ“„ users.py         # User management endpoints
â”‚   â”œâ”€â”€ ğŸ“„ topics.py        # Topic management
â”‚   â”œâ”€â”€ ğŸ“„ entries.py       # Journal entry CRUD
â”‚   â”œâ”€â”€ ğŸ“„ files.py         # File upload/download
â”‚   â”œâ”€â”€ ğŸ“„ tags.py          # Tag management
â”‚   â”œâ”€â”€ ğŸ“„ gallery.py       # Gallery management
â”‚   â””â”€â”€ ğŸ“„ ai.py            # AI integration endpoints
â””â”€â”€ ğŸ“ ai/                  # AI engine modules
    â”œâ”€â”€ ğŸ“„ agent.py         # LangChain Agent implementation
    â”œâ”€â”€ ğŸ“„ lm_studio.py     # LM Studio integration & streaming
    â”œâ”€â”€ ğŸ“„ sql_tool.py      # Database query tools
    â”œâ”€â”€ ï¿½ prompt_manager.py # Dynamic prompt management
    â””â”€â”€ ğŸ“„ prompts.json     # Prompt templates storage
```

### Frontend Structure (`/frontend`)
```
frontend/
â”œâ”€â”€ ğŸ“ app/                 # Next.js 15 App Router
â”‚   â”œâ”€â”€ ğŸ“„ layout.tsx       # Root layout component
â”‚   â”œâ”€â”€ ğŸ“„ page.tsx         # Home page
â”‚   â”œâ”€â”€ ğŸ“„ providers.tsx    # Context providers
â”‚   â”œâ”€â”€ ğŸ“ ai/             # AI chat interface
â”‚   â”œâ”€â”€ ğŸ“ entries/        # Journal entry management
â”‚   â”œâ”€â”€ ğŸ“ topics/         # Topic management
â”‚   â”œâ”€â”€ ğŸ“ auth/           # Authentication pages
â”‚   â””â”€â”€ ğŸ“ profile/        # User profile management
â”œâ”€â”€ ğŸ“ components/         # Reusable React components
â”‚   â”œâ”€â”€ ğŸ“„ Header.tsx      # Navigation header
â”‚   â”œâ”€â”€ ğŸ“„ MarkdownEditor.tsx # Rich text editor
â”‚   â”œâ”€â”€ ğŸ“„ EmojiPicker.tsx # Emoji selection
â”‚   â”œâ”€â”€ ğŸ“ AI/             # AI-specific components
â”‚   â””â”€â”€ ğŸ“ Navigation/     # Navigation components
â”œâ”€â”€ ğŸ“ lib/                # Utility libraries
â”‚   â”œâ”€â”€ ğŸ“„ ai-utils.ts     # AI integration utilities
â”‚   â”œâ”€â”€ ï¿½ api.ts          # API client configuration
â”‚   â””â”€â”€ ğŸ“„ auth.ts         # Authentication utilities
â”œâ”€â”€ ğŸ“ types/              # TypeScript type definitions
â”‚   â”œâ”€â”€ ğŸ“„ api.ts          # API response types
â”‚   â”œâ”€â”€ ğŸ“„ auth.ts         # Authentication types
â”‚   â””â”€â”€ ğŸ“„ ai.ts           # AI-related types
â””â”€â”€ ğŸ“ public/             # Static assets
    â”œâ”€â”€ ğŸ“„ favicon.ico
    â””â”€â”€ ğŸ“ images/
```

## ğŸ›¡ï¸ Security & Best Practices

### Authentication & Authorization
- **JWT tokens** vá»›i expiration vÃ  refresh mechanism
- **Password hashing** sá»­ dá»¥ng bcrypt vá»›i salt
- **Role-based permissions** cho admin functions
- **API rate limiting** Ä‘á»ƒ prevent abuse

### Data Protection
- **Input validation** vá»›i Pydantic schemas
- **SQL injection protection** vá»›i SQLAlchemy ORM
- **File upload security** vá»›i type checking vÃ  size limits
- **CORS configuration** cho cross-origin requests

### Performance Optimization
- **Database indexing** cho search performance
- **Connection pooling** cho database efficiency
- **Caching strategies** cho frequent queries
- **Async operations** cho I/O bound tasks

## ğŸ”§ Configuration & Customization

### AI Model Configuration
```python
# app/ai/lm_studio.py
LM_STUDIO_CONFIG = {
    "base_url": "http://localhost:1234/v1",
    "model": "llama-2-7b-chat",
    "temperature": 0.7,
    "max_tokens": 2048,
    "stream": True
}
```

### Database Customization
```python
# app/database.py
DATABASE_CONFIG = {
    "pool_size": 20,
    "max_overflow": 30,
    "pool_timeout": 30,
    "pool_recycle": 3600
}
```

## ğŸ“ˆ Monitoring & Logging

### Application Monitoring
- **Structured logging** vá»›i contextual information
- **Performance metrics** tracking (response times, throughput)
- **Error tracking** vá»›i detailed stack traces
- **Health checks** cho system components

### AI Model Monitoring  
- **Token usage tracking** cho cost management
- **Model performance metrics** (latency, accuracy)
- **Request/response logging** for debugging
- **Model switching** based on performance

## ğŸ¤ Contributing

### Development Workflow
1. **Fork** repository vÃ  create feature branch
2. **Follow coding standards** (Black, isort, mypy)
3. **Write tests** cho new features
4. **Update documentation** náº¿u cáº§n
5. **Submit pull request** vá»›i clear description

### Code Standards
```bash
# Format code
black app/ tests/
isort app/ tests/

# Type checking
mypy app/

# Linting
flake8 app/ tests/
```

### Commit Message Convention
```
feat: add new AI analysis feature
fix: resolve database connection issue  
docs: update installation guide
test: add unit tests for auth module
refactor: optimize database queries
```

## ï¿½ Support & Community

### Getting Help
- **GitHub Issues**: Report bugs vÃ  feature requests
- **Discussions**: Community Q&A vÃ  ideas
- **Documentation**: Comprehensive guides trong `/docs`
- **Email**: support@tcclog.com

### Resources
- [API Documentation](http://localhost:8000/docs)
- [Frontend Components Guide](./frontend/README.md)
- [Database Schema](./docs/database-schema.md)
- [AI Integration Guide](./docs/ai-integration.md)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **FastAPI** team cho excellent framework
- **LangChain** community cho AI integration tools
- **Next.js** team cho modern React framework
- **PostgreSQL** vÃ  **PGVector** cho powerful database capabilities

---

**Made with â¤ï¸ by TCC Log Team**

*Transforming learning through intelligent technology*
- Custom Theme Support: TÃ¹y chá»‰nh theo theme yÃªu thÃ­ch
- Batch Generation: Táº¡o nhiá»u prompts cÃ¹ng lÃºc
```

#### ğŸ”§ Advanced AI Features
```
âš¡ Technical Capabilities
- Server-Sent Events (SSE) streaming
- Chunk-based response processing
- Error handling vá»›i retry logic
- Response caching vÃ  optimization
- Model health monitoring
- Timeout protection cho long-running tasks
```

## ğŸš€ CÃ i Ä‘áº·t vá»›i Docker (Khuyáº¿n nghá»‹)

### On Windows (PowerShell)
```powershell
# Run the setup script
.\scripts\run_docker.ps1
```

This will:
1. Build the Docker images
2. Start the containers (PostgreSQL, Backend, Frontend)
3. Run migrations
4. Make the application available at:
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs
   - AI Chat Interface: http://localhost:3000/ai

### Manual Docker Setup
```bash
# Stop any running containers
docker-compose down

# Build the images
docker-compose build

# Start the containers
docker-compose up -d

# Run migrations (if needed)
docker-compose exec backend python -m alembic upgrade head
```

## ğŸ› ï¸ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng phÃ¡t triá»ƒn

### 1. Thiáº¿t láº­p Backend vá»›i AI Support
```bash
# Táº¡o conda environment
conda create -n tcc_log python=3.10 -y
conda activate tcc_log

# CÃ i Ä‘áº·t táº¥t cáº£ dependencies (bao gá»“m AI packages)
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh AI Services

Äá»ƒ cÃ i Ä‘áº·t cÃ¡c file mÃ´i trÆ°á»ng (.env) cáº§n thiáº¿t cho dá»± Ã¡n, vui lÃ²ng tham kháº£o [HÆ°á»›ng dáº«n Thiáº¿t láº­p MÃ´i trÆ°á»ng](docs/ENVIRONMENT_SETUP_GUIDE.md) chi tiáº¿t.

CÃ¡c biáº¿n mÃ´i trÆ°á»ng chÃ­nh cáº§n thiáº¿t láº­p:
```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/journal_db
SECRET_KEY=your-secret-key
ACCESS_TOKEN_EXPIRE_MINUTES=30

# LM Studio Configuration (Local AI)
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_MODEL=your-model-name
LM_MAX_INFERENCE_TIME=60000

# AI Behavior Settings
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000

# File Upload
MAX_FILE_SIZE_MB=10
ALLOWED_FILE_TYPES=jpg,jpeg,png,gif,pdf,doc,docx,txt,md
```

### 3. Database Setup
```bash
# Cháº¡y migrations
alembic upgrade head

# Náº¿u cáº§n táº¡o migration má»›i
alembic revision --autogenerate -m "Migration description"
```

### 4. Khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng
```bash
# Backend
python scripts/run_backend.py
# hoáº·c
uvicorn app.main:app --reload

# Frontend (terminal má»›i)
cd frontend
npm install
npm run dev
```

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
/
â”œâ”€â”€ app/                    # Backend FastAPI
â”‚   â”œâ”€â”€ ai/                # AI integration modules
â”‚   â”‚   â”œâ”€â”€ lm_studio.py   # LM Studio client & utilities
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ ai.py          # AI endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py        # Authentication
â”‚   â”‚   â”œâ”€â”€ entries.py     # Journal entries
â”‚   â”‚   â”œâ”€â”€ users.py       # User management
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ models.py          # Database models
â”‚   â”œâ”€â”€ schemas.py         # Pydantic schemas
â”‚   â””â”€â”€ main.py           # FastAPI app
â”œâ”€â”€ frontend/              # Next.js frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ ai/           # AI chat interface
â”‚   â”‚   â”œâ”€â”€ entries/      # Journal entries
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ AI/           # AI-related components
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ ai-utils.ts   # AI utility functions
â”‚       â””â”€â”€ ...
â”œâ”€â”€ scripts/               # Deployment scripts
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ uploads/               # User uploads
â”œâ”€â”€ alembic/               # Database migrations
â””â”€â”€ docker-compose.yml     # Docker configuration
```

## ğŸ¤– AI Integration chi tiáº¿t

### LM Studio Setup
1. **CÃ i Ä‘áº·t LM Studio**: Download tá»« [lmstudio.ai](https://lmstudio.ai)
2. **Load Model**: Download vÃ  load má»™t model
3. **Start Local Server**: Báº­t local server trong LM Studio (port 1234)
4. **Cáº¥u hÃ¬nh .env**: Äáº·t `LM_STUDIO_BASE_URL=http://localhost:1234/v1`

### AI Features Ä‘Ã£ tÃ­ch há»£p

#### ğŸ—¨ï¸ Chat Assistant (`/ai`)
- **Streaming Chat**: Real-time response vá»›i SSE
- **Think/Answer Separation**: Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh suy nghÄ© vÃ  káº¿t quáº£
- **LaTeX Support**: Render cÃ´ng thá»©c toÃ¡n há»c
- **Performance Metrics**: Token/giÃ¢y, thá»i gian inference
- **Model Selection**: Chá»n model tá»« LM Studio

#### ğŸ“Š Entry Analysis (`/api/ai/analyze-entry`)
- **4 loáº¡i phÃ¢n tÃ­ch**: General, Mood, Summary, Insights
- **Structured Output**: Think section + Answer
- **Multi-model Support**: Chá»n model cho tá»«ng phÃ¢n tÃ­ch

#### âœï¸ Writing Enhancement (`/api/ai/improve-writing`)
- **Grammar Correction**: Sá»­a lá»—i ngá»¯ phÃ¡p
- **Style Improvement**: Cáº£i thiá»‡n vÄƒn phong
- **Vocabulary Enhancement**: NÃ¢ng cao tá»« vá»±ng
- **Complete Polish**: Tá»‘i Æ°u toÃ n diá»‡n

### API Endpoints

```bash
# AI Service Status
GET /api/ai/status

# Available Models
GET /api/ai/models

# Chat (Non-streaming)
POST /api/ai/chat

# Chat (Streaming)
POST /api/ai/chat-stream

# Analyze Journal Entry
POST /api/ai/analyze-entry

# Improve Writing
POST /api/ai/improve-writing

# Writing Suggestions
POST /api/ai/writing-suggestions

# Generate Prompts
POST /api/ai/generate-prompts
```

## ğŸ“± Sá»­ dá»¥ng

### Workflow cÆ¡ báº£n:
1. **ÄÄƒng kÃ½/ÄÄƒng nháº­p** tÃ i khoáº£n
2. **Táº¡o Topics** Ä‘á»ƒ phÃ¢n loáº¡i ná»™i dung há»c táº­p
3. **Viáº¿t Journal Entries** vá»›i Markdown editor
4. **Upload files** Ä‘Ã­nh kÃ¨m náº¿u cáº§n
5. **Chat vá»›i AI** Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ há»c táº­p
6. **Analyze entries** Ä‘á»ƒ cÃ³ insights
7. **Improve writing** vá»›i AI suggestions

### AI Features Usage:
- **Chat**: VÃ o `/ai` Ä‘á»ƒ chat trá»±c tiáº¿p vá»›i AI
- **Analysis**: Click "Analyze" trÃªn journal entry
- **Writing Help**: Sá»­ dá»¥ng writing improvement tools
- **Prompts**: Generate prompts cho inspiration

## ğŸ”§ Development Commands

```bash
# Cháº¡y tests
python -m pytest tests/

# Format code
black app/
isort app/

# Type checking
mypy app/

# Database operations
alembic revision --autogenerate -m "Description"
alembic upgrade head
alembic downgrade -1

# AI service check
curl http://localhost:8000/api/ai/status
```

## ğŸ“„ Dependencies

### AI/ML Stack:
- **LangChain**: Framework cho AI applications
- **OpenAI**: Compatible API cho LM Studio
- **tiktoken**: Tokenization utilities
- **httpx**: Async HTTP client cho AI requests

### Backend Stack:
- **FastAPI**: Modern web framework
- **SQLAlchemy**: ORM cho database
- **Alembic**: Database migrations
- **Pydantic**: Data validation
- **PGVector**: Vector database extension

### Frontend Stack:
- **Next.js**: React framework
- **TailwindCSS**: Utility-first CSS
- **TypeScript**: Type safety

## ğŸ¤ Contributing

ÄÃ¢y lÃ  dá»± Ã¡n há»c táº­p cÃ¡ nhÃ¢n, má»i gÃ³p Ã½ vÃ  Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh!

## ğŸ“„ License

MIT License - Dá»± Ã¡n há»c táº­p cÃ¡ nhÃ¢n