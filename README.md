# ğŸš€ TCC Log - AI-Powered Learning Journal

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)](https://postgresql.org/)
[![LangChain](https://img.shields.io/badge/LangChain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white)](https://langchain.com/)

> **á»¨ng dá»¥ng ghi chÃº há»c táº­p thÃ´ng minh tÃ­ch há»£p AI** - NÃ¢ng cao tráº£i nghiá»‡m há»c táº­p vá»›i sá»©c máº¡nh cá»§a Artificial Intelligence

## ğŸ“– Tá»•ng quan

TCC Log lÃ  má»™t á»©ng dá»¥ng web hiá»‡n Ä‘áº¡i Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ há»— trá»£ há»c táº­p vÃ  tá»• chá»©c kiáº¿n thá»©c má»™t cÃ¡ch thÃ´ng minh. Vá»›i sá»± tÃ­ch há»£p sÃ¢u sáº¯c cá»§a AI vÃ  cÃ¡c cÃ´ng nghá»‡ tiÃªn tiáº¿n, á»©ng dá»¥ng cung cáº¥p má»™t ná»n táº£ng toÃ n diá»‡n cho viá»‡c ghi chÃº, phÃ¢n tÃ­ch vÃ  tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh há»c táº­p.

### ğŸ¯ Má»¥c tiÃªu
- **Tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh há»c táº­p** thÃ´ng qua AI-powered insights
- **Tá»± Ä‘á»™ng hÃ³a phÃ¢n tÃ­ch** ná»™i dung vÃ  cáº£m xÃºc trong cÃ¡c ghi chÃº
- **Cung cáº¥p trá»£ lÃ½ AI** thÃ´ng minh cho viá»‡c giáº£i Ä‘Ã¡p tháº¯c máº¯c
- **Tá»• chá»©c kiáº¿n thá»©c** má»™t cÃ¡ch khoa há»c vÃ  dá»… tÃ¬m kiáº¿m

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚   Database      â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚  (PostgreSQL)   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚   + PGVector    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   AI Engine     â”‚
                    â”‚  (LangChain +   â”‚
                    â”‚   LM Studio)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ› ï¸ Stack cÃ´ng nghá»‡

#### Backend
- **FastAPI** - Modern Python web framework vá»›i performance cao
- **SQLAlchemy** - ORM máº¡nh máº½ vá»›i async support
- **PostgreSQL** - Reliable database vá»›i PGVector extension
- **Alembic** - Database migration tool
- **Pydantic** - Data validation vÃ  serialization

#### Frontend  
- **Next.js 14** - React framework vá»›i App Router
- **TailwindCSS** - Utility-first CSS framework
- **TypeScript** - Type-safe development
- **React Hook Form** - Form handling vÃ  validation

#### AI/ML
- **LangChain** - Framework cho LLM applications
- **LM Studio** - Local AI model serving
- **OpenAI API** - External AI model integration
- **PGVector** - Vector similarity search

## âœ¨ TÃ­nh nÄƒng chÃ­nh

### ğŸ“ Quáº£n lÃ½ Journal thÃ´ng minh
- **Rich Text Editor** vá»›i há»— trá»£ Markdown vÃ  LaTeX
- **PhÃ¢n loáº¡i chá»§ Ä‘á»** (Topics) vá»›i hierarchy structure
- **Tag system** linh hoáº¡t cho viá»‡c tá»• chá»©c vÃ  tÃ¬m kiáº¿m
- **File upload** há»— trá»£ hÃ¬nh áº£nh, documents vÃ  multimedia
- **Profile management** vá»›i avatar vÃ  preferences cÃ¡ nhÃ¢n
- **Date-based organization** vá»›i calendar view

### ğŸ¤– AI-Powered Features

#### ğŸ’¬ Intelligent Chat Assistant
- **Interactive AI Chatbot** há»— trá»£ há»c táº­p 24/7
- **Context-aware responses** dá»±a trÃªn journal content
- **LaTeX rendering** cho cÃ´ng thá»©c toÃ¡n há»c
- **Streaming responses** vá»›i real-time feedback
- **Think/Answer separation** - theo dÃµi quÃ¡ trÃ¬nh suy nghÄ© AI
- **Performance monitoring** (tokens/second, inference time)

#### ğŸ“Š Advanced Content Analysis
- **General Analysis**: PhÃ¢n tÃ­ch tá»•ng quan ná»™i dung vÃ  cháº¥t lÆ°á»£ng
- **Mood Analysis**: ÄÃ¡nh giÃ¡ tráº¡ng thÃ¡i cáº£m xÃºc vÃ  mental health
- **Content Summary**: TÃ³m táº¯t key points vÃ  takeaways
- **Learning Insights**: TrÃ­ch xuáº¥t patterns vÃ  recommendations
- **Progress Tracking**: Theo dÃµi learning journey theo thá»i gian

#### âœï¸ Writing Enhancement
- **Grammar & Spell Check**: Tá»± Ä‘á»™ng detect vÃ  suggest fixes
- **Style Improvement**: Cáº£i thiá»‡n clarity vÃ  readability  
- **Vocabulary Enhancement**: Suggest synonyms vÃ  academic terms
- **Structure Analysis**: ÄÃ¡nh giÃ¡ logic flow vÃ  organization

#### ğŸ” Semantic Search
- **Vector-based search** vá»›i PGVector cho similarity matching
- **Natural language queries** thay vÃ¬ keyword search
- **Cross-reference suggestions** tÃ¬m related content
- **Auto-tagging** dá»±a trÃªn content analysis

### ğŸ” Security & Authentication
- **JWT-based authentication** vá»›i refresh token
- **Role-based access control** (User, Admin)
- **Password hashing** vá»›i bcrypt
- **Secure file upload** vá»›i type validation
- **API rate limiting** vÃ  request validation

## ğŸš€ CÃ i Ä‘áº·t vÃ  Triá»ƒn khai

### YÃªu cáº§u há»‡ thá»‘ng
- **Python 3.9+**
- **Node.js 18+** vÃ  npm/yarn
- **PostgreSQL 14+** vá»›i PGVector extension
- **LM Studio** (optional, for local AI models)

### ï¿½ Prerequisites

1. **Database Setup**
```bash
# Install PostgreSQL
# Ubuntu/Debian
sudo apt update
sudo apt install postgresql postgresql-contrib

# Windows (using chocolatey)
choco install postgresql

# macOS (using homebrew)  
brew install postgresql
```

2. **PGVector Extension**
```sql
-- Connect to PostgreSQL as superuser
CREATE EXTENSION IF NOT EXISTS vector;
```

### ğŸ”§ Installation

#### 1. Clone Repository
```bash
git clone https://github.com/your-username/tcc-log.git
cd tcc-log
```

#### 2. Backend Setup
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate
# macOS/Linux  
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

#### 3. Environment Configuration
```bash
# Copy environment template
cp .env.example .env

# Edit .env with your configurations
nano .env
```

**Environment Variables:**
```env
# Database
DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/tcc_log
TEST_DATABASE_URL=postgresql+psycopg2://username:password@localhost:5432/tcc_log_test

# Security
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI Configuration
OPENAI_API_KEY=your-openai-api-key
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_API_KEY=your-lm-studio-key

# File Upload
UPLOAD_DIR=uploads
MAX_FILE_SIZE=10485760  # 10MB
```

#### 4. Database Migration
```bash
# Initialize Alembic (if not done)
alembic init alembic

# Create and run migrations
alembic revision --autogenerate -m "Initial migration"
alembic upgrade head

# Seed sample data (optional)
python -m app.seed_data
```

#### 5. Frontend Setup
```bash
cd frontend

# Install dependencies
npm install
# or
yarn install

# Create environment file
cp .env.local.example .env.local

# Edit frontend environment
nano .env.local
```

**Frontend Environment:**
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_APP_NAME=TCC Log
NEXT_PUBLIC_MAX_FILE_SIZE=10485760
```

### ğŸ® Running the Application

#### Development Mode

**Backend (Terminal 1):**
```bash
# From project root
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Frontend (Terminal 2):**
```bash
cd frontend
npm run dev
# or
yarn dev
```

**Access Points:**
- Frontend: http://localhost:3000
- Backend API: http://localhost:8000
- API Documentation: http://localhost:8000/docs
- Alternative API Docs: http://localhost:8000/redoc

#### Production Mode

**Using Docker Compose:**
```bash
# Build and start all services
docker-compose up --build

# Run in background
docker-compose up -d

# Stop services
docker-compose down
```

**Manual Production Setup:**
```bash
# Backend
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000

# Frontend  
cd frontend
npm run build
npm start
```

### ğŸ”§ LM Studio Configuration

1. **Download vÃ  Install LM Studio** tá»« https://lmstudio.ai/
2. **Download AI Models** (vÃ­ dá»¥: Llama, Mistral, CodeLlama)
3. **Start Local Server:**
   ```
   - Má»Ÿ LM Studio
   - Chá»n model vÃ  click "Start Server"
   - Default URL: http://localhost:1234/v1
   ```
4. **Configure trong .env:**
   ```env
   LM_STUDIO_BASE_URL=http://localhost:1234/v1
   LM_STUDIO_API_KEY=lm-studio  # hoáº·c key cá»§a báº¡n
   ```

## ğŸ§ª Testing

### Running Tests
```bash
# Install test dependencies
pip install pytest pytest-asyncio pytest-cov

# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test files
pytest tests/test_auth.py
pytest tests/test_ai_features.py
```

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
tcc_log/
â”œâ”€â”€ ğŸ“ app/                  # Backend application
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py             # FastAPI application entry
â”‚   â”œâ”€â”€ database.py         # Database configuration
â”‚   â”œâ”€â”€ models.py           # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas.py          # Pydantic schemas
â”‚   â”œâ”€â”€ crud.py             # Database operations
â”‚   â”œâ”€â”€ ğŸ“ api/             # API routes
â”‚   â”‚   â”œâ”€â”€ auth.py         # Authentication endpoints
â”‚   â”‚   â”œâ”€â”€ users.py        # User management
â”‚   â”‚   â”œâ”€â”€ topics.py       # Topic management
â”‚   â”‚   â”œâ”€â”€ entries.py      # Journal entries
â”‚   â”‚   â”œâ”€â”€ files.py        # File upload/download
â”‚   â”‚   â””â”€â”€ ai.py           # AI integration endpoints
â”‚   â””â”€â”€ ğŸ“ ai/              # AI modules
â”‚       â”œâ”€â”€ agent.py        # Main AI agent
â”‚       â”œâ”€â”€ lm_studio.py    # LM Studio integration
â”‚       â””â”€â”€ sql_tool.py     # Database query tool
â”œâ”€â”€ ğŸ“ frontend/             # Next.js frontend
â”‚   â”œâ”€â”€ app/                # App router pages
â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”œâ”€â”€ lib/                # Utility libraries
â”‚   â”œâ”€â”€ types/              # TypeScript types
â”‚   â””â”€â”€ public/             # Static assets
â”œâ”€â”€ ğŸ“ tests/               # Test suite
â”‚   â”œâ”€â”€ conftest.py         # Test configuration
â”‚   â”œâ”€â”€ unit/               # Unit tests
â”‚   â”œâ”€â”€ integration/        # Integration tests
â”‚   â””â”€â”€ config/             # Test configs
â”œâ”€â”€ ğŸ“ alembic/             # Database migrations
â”œâ”€â”€ ğŸ“ docs/                # Documentation
â”œâ”€â”€ ğŸ“ scripts/             # Utility scripts
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ docker-compose.yml      # Docker orchestration
â”œâ”€â”€ .env.example            # Environment template
â””â”€â”€ README.md               # This file
```

## ğŸ›¡ï¸ Security & Best Practices

### Authentication & Authorization
- **JWT tokens** vá»›i expiration vÃ  refresh mechanism
- **Password hashing** sá»­ dá»¥ng bcrypt vá»›i salt
- **Role-based permissions** cho admin functions
- **API rate limiting** Ä‘á»ƒ prevent abuse

### Data Protection
- **Input validation** vá»›i Pydantic schemas
- **SQL injection protection** vá»›i SQLAlchemy ORM
- **File upload security** vá»›i type checking vÃ  size limits
- **CORS configuration** cho cross-origin requests

### Performance Optimization
- **Database indexing** cho search performance
- **Connection pooling** cho database efficiency
- **Caching strategies** cho frequent queries
- **Async operations** cho I/O bound tasks

## ğŸ”§ Configuration & Customization

### AI Model Configuration
```python
# app/ai/lm_studio.py
LM_STUDIO_CONFIG = {
    "base_url": "http://localhost:1234/v1",
    "model": "llama-2-7b-chat",
    "temperature": 0.7,
    "max_tokens": 2048,
    "stream": True
}
```

### Database Customization
```python
# app/database.py
DATABASE_CONFIG = {
    "pool_size": 20,
    "max_overflow": 30,
    "pool_timeout": 30,
    "pool_recycle": 3600
}
```

## ğŸ“ˆ Monitoring & Logging

### Application Monitoring
- **Structured logging** vá»›i contextual information
- **Performance metrics** tracking (response times, throughput)
- **Error tracking** vá»›i detailed stack traces
- **Health checks** cho system components

### AI Model Monitoring  
- **Token usage tracking** cho cost management
- **Model performance metrics** (latency, accuracy)
- **Request/response logging** for debugging
- **Model switching** based on performance

## ğŸ¤ Contributing

### Development Workflow
1. **Fork** repository vÃ  create feature branch
2. **Follow coding standards** (Black, isort, mypy)
3. **Write tests** cho new features
4. **Update documentation** náº¿u cáº§n
5. **Submit pull request** vá»›i clear description

### Code Standards
```bash
# Format code
black app/ tests/
isort app/ tests/

# Type checking
mypy app/

# Linting
flake8 app/ tests/
```

### Commit Message Convention
```
feat: add new AI analysis feature
fix: resolve database connection issue  
docs: update installation guide
test: add unit tests for auth module
refactor: optimize database queries
```

## ï¿½ Support & Community

### Getting Help
- **GitHub Issues**: Report bugs vÃ  feature requests
- **Discussions**: Community Q&A vÃ  ideas
- **Documentation**: Comprehensive guides trong `/docs`
- **Email**: support@tcclog.com

### Resources
- [API Documentation](http://localhost:8000/docs)
- [Frontend Components Guide](./frontend/README.md)
- [Database Schema](./docs/database-schema.md)
- [AI Integration Guide](./docs/ai-integration.md)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **FastAPI** team cho excellent framework
- **LangChain** community cho AI integration tools
- **Next.js** team cho modern React framework
- **PostgreSQL** vÃ  **PGVector** cho powerful database capabilities

---

**Made with â¤ï¸ by TCC Log Team**

*Transforming learning through intelligent technology*
- Custom Theme Support: TÃ¹y chá»‰nh theo theme yÃªu thÃ­ch
- Batch Generation: Táº¡o nhiá»u prompts cÃ¹ng lÃºc
```

#### ğŸ”§ Advanced AI Features
```
âš¡ Technical Capabilities
- Server-Sent Events (SSE) streaming
- Chunk-based response processing
- Error handling vá»›i retry logic
- Response caching vÃ  optimization
- Model health monitoring
- Timeout protection cho long-running tasks
```

## ğŸš€ CÃ i Ä‘áº·t vá»›i Docker (Khuyáº¿n nghá»‹)

### On Windows (PowerShell)
```powershell
# Run the setup script
.\scripts\run_docker.ps1
```

This will:
1. Build the Docker images
2. Start the containers (PostgreSQL, Backend, Frontend)
3. Run migrations
4. Make the application available at:
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs
   - AI Chat Interface: http://localhost:3000/ai

### Manual Docker Setup
```bash
# Stop any running containers
docker-compose down

# Build the images
docker-compose build

# Start the containers
docker-compose up -d

# Run migrations (if needed)
docker-compose exec backend python -m alembic upgrade head
```

## ğŸ› ï¸ CÃ i Ä‘áº·t mÃ´i trÆ°á»ng phÃ¡t triá»ƒn

### 1. Thiáº¿t láº­p Backend vá»›i AI Support
```bash
# Táº¡o conda environment
conda create -n tcc_log python=3.10 -y
conda activate tcc_log

# CÃ i Ä‘áº·t táº¥t cáº£ dependencies (bao gá»“m AI packages)
pip install -r requirements.txt
```

### 2. Cáº¥u hÃ¬nh AI Services

Äá»ƒ cÃ i Ä‘áº·t cÃ¡c file mÃ´i trÆ°á»ng (.env) cáº§n thiáº¿t cho dá»± Ã¡n, vui lÃ²ng tham kháº£o [HÆ°á»›ng dáº«n Thiáº¿t láº­p MÃ´i trÆ°á»ng](docs/ENVIRONMENT_SETUP_GUIDE.md) chi tiáº¿t.

CÃ¡c biáº¿n mÃ´i trÆ°á»ng chÃ­nh cáº§n thiáº¿t láº­p:
```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/journal_db
SECRET_KEY=your-secret-key
ACCESS_TOKEN_EXPIRE_MINUTES=30

# LM Studio Configuration (Local AI)
LM_STUDIO_BASE_URL=http://localhost:1234/v1
LM_STUDIO_MODEL=your-model-name
LM_MAX_INFERENCE_TIME=60000

# AI Behavior Settings
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2000

# File Upload
MAX_FILE_SIZE_MB=10
ALLOWED_FILE_TYPES=jpg,jpeg,png,gif,pdf,doc,docx,txt,md
```

### 3. Database Setup
```bash
# Cháº¡y migrations
alembic upgrade head

# Náº¿u cáº§n táº¡o migration má»›i
alembic revision --autogenerate -m "Migration description"
```

### 4. Khá»Ÿi Ä‘á»™ng á»©ng dá»¥ng
```bash
# Backend
python scripts/run_backend.py
# hoáº·c
uvicorn app.main:app --reload

# Frontend (terminal má»›i)
cd frontend
npm install
npm run dev
```

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
/
â”œâ”€â”€ app/                    # Backend FastAPI
â”‚   â”œâ”€â”€ ai/                # AI integration modules
â”‚   â”‚   â”œâ”€â”€ lm_studio.py   # LM Studio client & utilities
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ ai.py          # AI endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py        # Authentication
â”‚   â”‚   â”œâ”€â”€ entries.py     # Journal entries
â”‚   â”‚   â”œâ”€â”€ users.py       # User management
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ models.py          # Database models
â”‚   â”œâ”€â”€ schemas.py         # Pydantic schemas
â”‚   â””â”€â”€ main.py           # FastAPI app
â”œâ”€â”€ frontend/              # Next.js frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ ai/           # AI chat interface
â”‚   â”‚   â”œâ”€â”€ entries/      # Journal entries
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ AI/           # AI-related components
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ ai-utils.ts   # AI utility functions
â”‚       â””â”€â”€ ...
â”œâ”€â”€ scripts/               # Deployment scripts
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ uploads/               # User uploads
â”œâ”€â”€ alembic/               # Database migrations
â””â”€â”€ docker-compose.yml     # Docker configuration
```

## ğŸ¤– AI Integration chi tiáº¿t

### LM Studio Setup
1. **CÃ i Ä‘áº·t LM Studio**: Download tá»« [lmstudio.ai](https://lmstudio.ai)
2. **Load Model**: Download vÃ  load má»™t model
3. **Start Local Server**: Báº­t local server trong LM Studio (port 1234)
4. **Cáº¥u hÃ¬nh .env**: Äáº·t `LM_STUDIO_BASE_URL=http://localhost:1234/v1`

### AI Features Ä‘Ã£ tÃ­ch há»£p

#### ğŸ—¨ï¸ Chat Assistant (`/ai`)
- **Streaming Chat**: Real-time response vá»›i SSE
- **Think/Answer Separation**: Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh suy nghÄ© vÃ  káº¿t quáº£
- **LaTeX Support**: Render cÃ´ng thá»©c toÃ¡n há»c
- **Performance Metrics**: Token/giÃ¢y, thá»i gian inference
- **Model Selection**: Chá»n model tá»« LM Studio

#### ğŸ“Š Entry Analysis (`/api/ai/analyze-entry`)
- **4 loáº¡i phÃ¢n tÃ­ch**: General, Mood, Summary, Insights
- **Structured Output**: Think section + Answer
- **Multi-model Support**: Chá»n model cho tá»«ng phÃ¢n tÃ­ch

#### âœï¸ Writing Enhancement (`/api/ai/improve-writing`)
- **Grammar Correction**: Sá»­a lá»—i ngá»¯ phÃ¡p
- **Style Improvement**: Cáº£i thiá»‡n vÄƒn phong
- **Vocabulary Enhancement**: NÃ¢ng cao tá»« vá»±ng
- **Complete Polish**: Tá»‘i Æ°u toÃ n diá»‡n

### API Endpoints

```bash
# AI Service Status
GET /api/ai/status

# Available Models
GET /api/ai/models

# Chat (Non-streaming)
POST /api/ai/chat

# Chat (Streaming)
POST /api/ai/chat-stream

# Analyze Journal Entry
POST /api/ai/analyze-entry

# Improve Writing
POST /api/ai/improve-writing

# Writing Suggestions
POST /api/ai/writing-suggestions

# Generate Prompts
POST /api/ai/generate-prompts
```

## ğŸ“± Sá»­ dá»¥ng

### Workflow cÆ¡ báº£n:
1. **ÄÄƒng kÃ½/ÄÄƒng nháº­p** tÃ i khoáº£n
2. **Táº¡o Topics** Ä‘á»ƒ phÃ¢n loáº¡i ná»™i dung há»c táº­p
3. **Viáº¿t Journal Entries** vá»›i Markdown editor
4. **Upload files** Ä‘Ã­nh kÃ¨m náº¿u cáº§n
5. **Chat vá»›i AI** Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ há»c táº­p
6. **Analyze entries** Ä‘á»ƒ cÃ³ insights
7. **Improve writing** vá»›i AI suggestions

### AI Features Usage:
- **Chat**: VÃ o `/ai` Ä‘á»ƒ chat trá»±c tiáº¿p vá»›i AI
- **Analysis**: Click "Analyze" trÃªn journal entry
- **Writing Help**: Sá»­ dá»¥ng writing improvement tools
- **Prompts**: Generate prompts cho inspiration

## ğŸ”§ Development Commands

```bash
# Cháº¡y tests
python -m pytest tests/

# Format code
black app/
isort app/

# Type checking
mypy app/

# Database operations
alembic revision --autogenerate -m "Description"
alembic upgrade head
alembic downgrade -1

# AI service check
curl http://localhost:8000/api/ai/status
```

## ğŸ“„ Dependencies

### AI/ML Stack:
- **LangChain**: Framework cho AI applications
- **OpenAI**: Compatible API cho LM Studio
- **tiktoken**: Tokenization utilities
- **httpx**: Async HTTP client cho AI requests

### Backend Stack:
- **FastAPI**: Modern web framework
- **SQLAlchemy**: ORM cho database
- **Alembic**: Database migrations
- **Pydantic**: Data validation
- **PGVector**: Vector database extension

### Frontend Stack:
- **Next.js**: React framework
- **TailwindCSS**: Utility-first CSS
- **TypeScript**: Type safety

## ğŸ¤ Contributing

ÄÃ¢y lÃ  dá»± Ã¡n há»c táº­p cÃ¡ nhÃ¢n, má»i gÃ³p Ã½ vÃ  Ä‘Ã³ng gÃ³p Ä‘á»u Ä‘Æ°á»£c hoan nghÃªnh!

## ğŸ“„ License

MIT License - Dá»± Ã¡n há»c táº­p cÃ¡ nhÃ¢n