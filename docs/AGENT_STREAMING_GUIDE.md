# Agent Streaming Guide

## Tá»•ng quan

Há»‡ thá»‘ng hiá»‡n táº¡i Ä‘Ã£ Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»ƒ há»— trá»£ streaming text trong agent mode, cho phÃ©p báº¡n nháº­n pháº£n há»“i theo thá»i gian thá»±c khi AI agent Ä‘ang xá»­ lÃ½.

## CÃ¡c loáº¡i Streaming

### 1. Basic Agent Streaming
Streaming cÆ¡ báº£n vá»›i agent mode, hiá»ƒn thá»‹ output cuá»‘i cÃ¹ng:

```python
from app.ai.lm_studio import chat_with_ai, create_default_tools

async def basic_streaming_example():
    async for chunk in chat_with_ai(
        message="What is 2 + 2?",
        streaming=True,
        use_agent=True,
        tools=create_default_tools()
    ):
        print(chunk, end="", flush=True)
```

### 2. Enhanced Agent Streaming
Streaming chi tiáº¿t vá»›i thÃ´ng tin vá» tool usage vÃ  thinking process:

```python
from app.ai.lm_studio import chat_with_ai_agent_enhanced_streaming

async def enhanced_streaming_example():
    async for event_chunk in chat_with_ai_agent_enhanced_streaming(
        message="Calculate something and search for info",
        tools=create_default_tools()
    ):
        print(event_chunk, end="", flush=True)
```

### 3. Regular Streaming (Non-Agent)
Streaming thÃ´ng thÆ°á»ng khÃ´ng dÃ¹ng agent:

```python
async def regular_streaming_example():
    async for chunk in chat_with_ai(
        message="Explain something",
        streaming=True,
        use_agent=False  # KhÃ´ng dÃ¹ng agent
    ):
        print(chunk, end="", flush=True)
```

## Features cá»§a Agent Streaming

### ğŸ¤” Thinking Process
- Hiá»ƒn thá»‹ quÃ¡ trÃ¬nh suy nghÄ© cá»§a AI agent
- ThÃ´ng bÃ¡o khi agent Ä‘ang láº­p káº¿ hoáº¡ch

### ğŸ”§ Tool Usage Indicators  
- ThÃ´ng bÃ¡o khi agent báº¯t Ä‘áº§u sá»­ dá»¥ng tools
- Hiá»ƒn thá»‹ káº¿t quáº£ tá»« tools
- Theo dÃµi quÃ¡ trÃ¬nh thá»±c thi tools

### ğŸ“‹ Result Streaming
- Stream káº¿t quáº£ trá»±c tiáº¿p tá»« LLM
- Hiá»ƒn thá»‹ output cuá»‘i cÃ¹ng tá»« agent

### âœ… Completion Status
- ThÃ´ng bÃ¡o khi agent hoÃ n thÃ nh task
- Tá»•ng há»£p káº¿t quáº£ cuá»‘i cÃ¹ng

## Cáº¥u hÃ¬nh vÃ  Setup

### Environment Variables
Äáº£m báº£o báº¡n Ä‘Ã£ cáº¥u hÃ¬nh:

```bash
# LM Studio configuration
LM_STUDIO_BASE_URL=http://127.0.0.1:1234/v1
LM_STUDIO_MODEL=your-model-name
LM_MAX_INFERENCE_TIME=60000

# Database (optional, for PostgreSQL tools)
DATABASE_URL=postgresql://user:password@host:port/dbname
```

### Tools Configuration
Agent cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c tools sau:

#### Default Tools:
- **search**: TÃ¬m kiáº¿m thÃ´ng tin
- **calculator**: Thá»±c hiá»‡n tÃ­nh toÃ¡n

#### PostgreSQL Tools (tá»± Ä‘á»™ng thÃªm náº¿u cÃ³ DATABASE_URL):
- **database_query**: Thá»±c thi SQL queries
- **get_database_schema**: Láº¥y schema database
- **analyze_query**: PhÃ¢n tÃ­ch SQL query
- **get_table_info**: ThÃ´ng tin chi tiáº¿t vá» table
- **inspect_data**: Xem máº«u dá»¯ liá»‡u
- **get_table_relationships**: Má»‘i quan há»‡ giá»¯a tables
- **get_table_sizes**: KÃ­ch thÆ°á»›c cá»§a tables

## Sá»­ dá»¥ng trong Application

### FastAPI Endpoint Example
```python
from fastapi import FastAPI
from fastapi.responses import StreamingResponse
import json

app = FastAPI()

@app.post("/chat/stream")
async def stream_chat(request: ChatRequest):
    async def generate():
        async for chunk in chat_with_ai(
            message=request.message,
            streaming=True,
            use_agent=request.use_agent,
            tools=create_default_tools()
        ):
            yield f"data: {json.dumps({'content': chunk})}\n\n"
    
    return StreamingResponse(generate(), media_type="text/plain")
```

### WebSocket Example
```python
@app.websocket("/ws/chat")
async def websocket_chat(websocket: WebSocket):
    await websocket.accept()
    
    while True:
        data = await websocket.receive_text()
        message_data = json.loads(data)
        
        async for chunk in chat_with_ai(
            message=message_data["message"],
            streaming=True,
            use_agent=True
        ):
            await websocket.send_text(json.dumps({
                "type": "chunk",
                "content": chunk
            }))
```

## Testing

Cháº¡y test script Ä‘á»ƒ kiá»ƒm tra streaming:

```bash
python test_agent_streaming.py
```

Test script sáº½ kiá»ƒm tra:
- âœ… Basic agent streaming
- âœ… Enhanced agent streaming vá»›i detailed events
- âœ… Regular non-agent streaming (Ä‘á»ƒ so sÃ¡nh)
- âœ… Database agent streaming (náº¿u cÃ³ DATABASE_URL)

## Troubleshooting

### Common Issues:

1. **Agent khÃ´ng stream**: 
   - Kiá»ƒm tra LM Studio cÃ³ Ä‘ang cháº¡y khÃ´ng
   - XÃ¡c nháº­n model Ä‘Ã£ Ä‘Æ°á»£c load

2. **Tools khÃ´ng hoáº¡t Ä‘á»™ng**:
   - Kiá»ƒm tra DATABASE_URL (cho PostgreSQL tools)
   - Verify tools Ä‘Æ°á»£c khá»Ÿi táº¡o Ä‘Ãºng cÃ¡ch

3. **Streaming bá»‹ cháº­m**:
   - TÄƒng `LM_MAX_INFERENCE_TIME` 
   - Kiá»ƒm tra network latency Ä‘áº¿n LM Studio

4. **Empty chunks**:
   - Code Ä‘Ã£ Ä‘Æ°á»£c filter Ä‘á»ƒ chá»‰ yield non-empty chunks
   - Check logs Ä‘á»ƒ debug

### Debug Tips:

Enable detailed logging:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

Check agent status vá»›i color indicators:
- ğŸŸ¢ **[AGENT MODE ACTIVE]**: Agent Ä‘ang hoáº¡t Ä‘á»™ng
- ğŸ”µ **[NON-AGENT MODE]**: Cháº¿ Ä‘á»™ thÃ´ng thÆ°á»ng  
- ğŸ”´ **[AGENT FAILED]**: Agent lá»—i, fallback to non-agent
- ğŸŒŠ **Starting streaming**: Báº¯t Ä‘áº§u streaming
- ğŸ” **Starting detailed streaming**: Enhanced streaming mode

## API Reference

### chat_with_ai()
```python
async def chat_with_ai(
    message: str,
    history: List[Dict[str, str]] = None,
    model: Optional[str] = None,
    system_prompt: Optional[str] = None,
    streaming: bool = False,
    use_agent: bool = False,
    tools: Optional[List[Tool]] = None
):
```

### chat_with_ai_agent_enhanced_streaming()
```python
async def chat_with_ai_agent_enhanced_streaming(
    message: str,
    model: Optional[str] = None,
    system_prompt: Optional[str] = None,
    tools: Optional[List[Tool]] = None
):
```

### LangChainAgent Methods
```python
# Basic streaming
async def chat(self, message: str, streaming: bool = False)

# Enhanced streaming with events
async def astream_events(self, message: str)
```

## Best Practices

1. **Always handle exceptions** trong streaming loops
2. **Filter empty chunks** Ä‘á»ƒ trÃ¡nh hiá»ƒn thá»‹ content trá»‘ng
3. **Use flush=True** khi print streaming content
4. **Implement timeout** cho streaming operations
5. **Provide visual indicators** cho user vá» tráº¡ng thÃ¡i streaming
6. **Test vá»›i different message types** Ä‘á»ƒ ensure robustness

---

Vá»›i implementation nÃ y, báº¡n giá» Ä‘Ã£ cÃ³ thá»ƒ sá»­ dá»¥ng streaming text trong agent mode má»™t cÃ¡ch mÆ°á»£t mÃ  vÃ  chi tiáº¿t! ğŸ‰ 